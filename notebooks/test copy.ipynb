{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "SUMMARIZE_MODEL_OCID = os.getenv('SUMMARIZE_MODEL_OCID') \n",
    "GEN_AI_INFERENCE_ENDPOINT = os.getenv('GEN_AI_INFERENCE_ENDPOINT') \n",
    "COMPARTMENT_ID = os.getenv('COMPARTMENT_ID') \n",
    "GENERATION_MODEL_OCID = os.getenv('GENERATION_MODEL_OCID') \n",
    "GEN_AI_ENDPOINT = os.getenv('GEN_AI_ENDPOINT') \n",
    "GENERATION_MODEL_OCID_llam = os.getenv('GENERATION_MODEL_OCID_llam') \n",
    "\n",
    "\n",
    "\n",
    "import oci\n",
    "config = oci.config.from_file()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "# Function to wrap text at 80 characters per line while keeping sentences intact\n",
    "def wrap_text_by_sentence(text, target_language_code, width=80):\n",
    "    if target_language_code == 'ja':\n",
    "        sentences = text.split(\"。\")  # Split text into sentences based on period (。)\n",
    "    else:\n",
    "        sentences = text.split(\". \") \n",
    "    wrapped_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if sentence:\n",
    "            # Wrap each sentence with a width of 80 characters\n",
    "            wrapped_sentence = textwrap.fill(sentence + \"。\", width=width)\n",
    "            wrapped_sentences.append(wrapped_sentence)\n",
    "    return \"\\n\".join(wrapped_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## translate with OCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# translate methord made with ai_language\n",
    "def translate_and_wrap_text(text_from, compartment_id, source_language_code, target_language_code):\n",
    "    # Initialize service client with default config file\n",
    "    ai_language_client = oci.ai_language.AIServiceLanguageClient(config)\n",
    "    \n",
    "    # Send the request to service, some parameters are not required, see API doc for more info\n",
    "    batch_language_translation_response = ai_language_client.batch_language_translation(\n",
    "        batch_language_translation_details=oci.ai_language.models.BatchLanguageTranslationDetails(\n",
    "            documents=[\n",
    "                oci.ai_language.models.TextDocument(\n",
    "                    key=\"1\",\n",
    "                    text=text_from,\n",
    "                    language_code=source_language_code)],\n",
    "            compartment_id=compartment_id,\n",
    "            target_language_code=target_language_code),\n",
    "        opc_request_id=\"VUPH6Z9C2LD99QDZBJODaaaaaaaamlgyvhoa4qvxzsoguxpdo62juyzpnaxscwq3n5kaxptrha5ihy4a\")\n",
    "    \n",
    "    # Get the data from response\n",
    "    translated_text = batch_language_translation_response.data.documents[0].translated_text\n",
    "    \n",
    "    # Wrap the translated text by sentence\n",
    "    wrapped_text = wrap_text_by_sentence(translated_text,target_language_code)\n",
    "    \n",
    "    return wrapped_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "適切な廃棄物管理は、すべての生活システムの健全性に不可欠です。\n",
      "私たちの助成金には、ナイジェリアのラゴスの社会企業であるウェサイクラーズ、人口密集した都市部での廃棄物リサイクルを奨励するウェサイクラーズ、ケニアのナイロビのW\n",
      "EEEセンター、電子廃棄物の環境および健康上の危険に対する公衆の認識を促進し、再利用、リサイクル、および安全な処分について市民に教育する。\n",
      "OracleはCalifornia Coastal Cleanup\n",
      "Dayの創設スポンサーでもあり、1995年以来、毎年何十万ポンドものゴミをCalifornia Waterwaysから削除しています。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "text_from = \"Proper waste management is essential to the health of all living systems. Our grantees include Wecyclers, a social enterprise in Lagos, Nigeria, that incentives waste recycling in densely populated urban neighbourhoods, and the WEEE Centre in Nairobi, Kenya, which promotes public awareness of the environmental and health hazards of e-waste and educates the public about reuse, recycling, and safe disposal. Oracle is also a founding sponsor of California Coastal Cleanup Day, which has removed hundreds of thousands of pounds of trash from California waterways each year since 1995\"\n",
    "source_language_code = \"en\"\n",
    "target_language_code = \"ja\"\n",
    "\n",
    "translated_and_wrapped_text = translate_and_wrap_text(text_from, COMPARTMENT_ID, source_language_code, target_language_code)\n",
    "print(translated_and_wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proper waste management is essential to the health of all living systems。\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text_from = \"適切な廃棄物管理は、すべての生活システムの健全性に不可欠です\"\n",
    "source_language_code = \"ja\"\n",
    "target_language_code = \"en\"\n",
    "\n",
    "translated_and_wrapped_text = translate_and_wrap_text(text_from, COMPARTMENT_ID, source_language_code, target_language_code)\n",
    "print(translated_and_wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  generate with meta.llama-2-70b-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_job_description(llam_model_ocid, endpoint, compartment_id, prompt):\n",
    "    generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(\n",
    "        config=config,\n",
    "        service_endpoint=endpoint,\n",
    "        retry_strategy=oci.retry.NoneRetryStrategy(),\n",
    "        timeout=(10, 240)\n",
    "    )\n",
    "\n",
    "    generate_text_detail = oci.generative_ai_inference.models.GenerateTextDetails()\n",
    "    llam_inference_request = oci.generative_ai_inference.models.LlamaLlmInferenceRequest()\n",
    "    llam_inference_request.prompt = prompt\n",
    "\n",
    "    llam_inference_request.max_tokens = 600\n",
    "    llam_inference_request.temperature = 1\n",
    "    llam_inference_request.frequency_penalty = 0\n",
    "    llam_inference_request.top_p = 0.75\n",
    "\n",
    "    generate_text_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=llam_model_ocid)\n",
    "    generate_text_detail.inference_request = llam_inference_request\n",
    "    generate_text_detail.compartment_id = compartment_id\n",
    "\n",
    "    generate_text_response = generative_ai_inference_client.generate_text(generate_text_detail)\n",
    "\n",
    "    return generate_text_response.data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "prompt = \"\"\"\n",
    "Generate a job description for a data visualization expert with the following three qualifications only:\n",
    "1) At least 5 years of data visualization expert\n",
    "2) A great eye for details\n",
    "3) Ability to create original visualizations\n",
    "\"\"\"\n",
    "\n",
    "generated_text = generate_job_description(GENERATION_MODEL_OCID_llam, GEN_AI_INFERENCE_ENDPOINT, COMPARTMENT_ID,prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************Generate Texts Result**************************\n",
      "\n",
      "Job Title: Data Visualization Expert\n",
      "\n",
      "Job Summary:\n",
      "We are seeking a highly skilled and experienced Data Visualization Expert to join our team. The successful candidate will have at least 5 years of experience in data visualization, a great eye for details, and the ability to create original visualizations. The Data Visualization Expert will be responsible for creating and maintaining high-quality data visualizations that effectively communicate complex data insights to both technical and non-technical audiences.\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "* Design and develop data visualizations that effectively communicate complex data insights to both technical and non-technical audiences.\n",
      "* Work closely with data analysts and data scientists to understand data sets and identify key insights.\n",
      "* Create original visualizations that are both aesthetically pleasing and informative.\n",
      "* Ensure that all visualizations are accurate, up-to-date, and easy to understand.\n",
      "* Collaborate with stakeholders to understand their data visualization needs and preferences.\n",
      "* Develop and maintain data visualization standards and best practices.\n",
      "* Stay up-to-date with the latest trends and tools in data visualization.\n",
      "\n",
      "Requirements:\n",
      "\n",
      "* At least 5 years of experience in data visualization.\n",
      "* A great eye for details.\n",
      "* Ability to create original visualizations.\n",
      "* Strong experience with data visualization tools such as Tableau, Power BI, D3.js, or equivalent.\n",
      "* Strong knowledge of data analysis and data modeling techniques.\n",
      "* Excellent communication and collaboration skills.\n",
      "* Strong attention to detail and ability to work independently.\n",
      "* Ability to work in a fast-paced environment and meet tight deadlines.\n",
      "* Bachelor's degree in Computer Science, Data Science, Statistics, or a related field.\n",
      "\n",
      "Nice to Have:\n",
      "\n",
      "* Master's degree in Computer Science, Data Science, Statistics, or a related field.\n",
      "* Experience with machine learning and data science techniques.\n",
      "* Experience with cloud-based data visualization platforms.\n",
      "* Familiarity with data governance and data quality principles.\n",
      "* Certification in data visualization or a related field.\n",
      "\n",
      "We Offer:\n",
      "\n",
      "* Competitive salary and benefits package.\n",
      "* Opportunities for career growth and professional development.\n",
      "* Collaborative and dynamic work environment.\n",
      "* Access to cutting-edge tools and technologies.\n",
      "* Flexible work arrangements and remote work options.\n",
      "\n",
      "How to Apply:\n",
      "\n",
      "If you are a motivated and experienced data visualization professional looking for a new challenge, please submit your application, including your resume, cover letter, and portfolio of work. We look forward to\n"
     ]
    }
   ],
   "source": [
    "print(\"**************************Generate Texts Result**************************\")\n",
    "generated_result = generated_text.inference_response.choices[0].text\n",
    "print(generated_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  generate with cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeAiClient:\n",
    "    def __init__(self, config, service_endpoint):\n",
    "        self.config = config\n",
    "        self.service_endpoint = service_endpoint\n",
    "\n",
    "    def generate_job_description(self, prompt, compartment_id, serving_mode, model_id, max_tokens, num_generations):\n",
    "        gen_ai_inference_client = GenerativeAiInferenceClient(\n",
    "            config=self.config,\n",
    "            service_endpoint=self.service_endpoint\n",
    "        )\n",
    "\n",
    "        generate_text_response = gen_ai_inference_client.generate_text(\n",
    "            generate_text_details=GenerateTextDetails(\n",
    "                compartment_id=compartment_id,\n",
    "                serving_mode=serving_mode,\n",
    "                inference_request=CohereLlmInferenceRequest(\n",
    "                    prompt=prompt,\n",
    "                    is_stream=False,\n",
    "                    max_tokens=max_tokens,\n",
    "                    num_generations=num_generations\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return generate_text_response.data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"inference_response\": {\n",
      "    \"generated_texts\": [\n",
      "      {\n",
      "        \"finish_reason\": null,\n",
      "        \"id\": \"0ff0fbe3-1123-4a4c-acb3-45ba45b993c3\",\n",
      "        \"likelihood\": null,\n",
      "        \"text\": \" We're looking for a talented Data Visualization Expert to join our team! The ideal candidate will have at least 5 years of experience in creating compelling and effective data visualizations, as well as an excellent eye for detail and the ability to create original visualizations that effectively communicate complex data insights.\\n\\nAs a Data Visualization Expert, you will be responsible for designing and developing visual representations of data and information to help stakeholders understand and interpret important trends and insights. You will work closely with our team of data analysts and scientists to understand the data and the story it needs to tell.\\n\\nYour responsibilities will include:\\n\\nDeveloping creative and innovative data visualizations that effectively communicate complex data insights to a variety of audiences.\\n\\nWorking closely with stakeholders to understand their data needs and translate them into actionable visual representations.\\n\\nConducting thorough research and analysis to determine the best ways to visualize data to support business goals and objectives.\\n\\nProficiency in designing data visualizations for both print and digital media.\\n\\nExcellent communication skills to effectively explain data concepts and findings to both technical and non-technical stakeholders.\\n\\nWe are looking for someone who is passionate about data and has a proven track record of creating effective data visualizations. If you have excellent attention to detail, are solution-oriented, and can thrive in a fast-paced environment, we want to hear from you! \\n\\nDoes this sound like a good fit for you? Please apply with your portfolio that showcases your experience and talents. We can't wait to see what you can bring to the team! \\n\\nWe look forward to receiving your application. \\n\\nSincerely,\\n[Your Name]\\n[Company Name]\\n\\n\",\n",
      "        \"token_likelihoods\": null\n",
      "      }\n",
      "    ],\n",
      "    \"prompt\": null,\n",
      "    \"runtime_type\": \"COHERE\",\n",
      "    \"time_created\": \"2024-04-05T03:41:25.416000+00:00\"\n",
      "  },\n",
      "  \"model_id\": \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyafhwal37hxwylnpbcncidimbwteff4xha77n5xz4m7p6a\",\n",
      "  \"model_version\": \"15.6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "gen_ai_client = GenerativeAiClient(config=config, service_endpoint=GEN_AI_INFERENCE_ENDPOINT)\n",
    "\n",
    "prompt = \"\"\"\n",
    "Generate a job description for a data visualization expert with the following three qualifications only:\n",
    "1) At least 5 years of data visualization expert\n",
    "2) A great eye for details\n",
    "3) Ability to create original visualizations\n",
    "\"\"\"\n",
    "\n",
    "serving_mode = OnDemandServingMode(model_id=GENERATION_MODEL_OCID)\n",
    "max_tokens = 906\n",
    "num_generations = 1\n",
    "\n",
    "generated_text = gen_ai_client.generate_job_description(prompt, COMPARTMENT_ID, serving_mode, GENERATION_MODEL_OCID, max_tokens, num_generations)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import re\n",
    "\n",
    "def wrap_text_by_sentence(text, target_language_code, width=60):\n",
    "    # Choose the correct delimiter based on the target language\n",
    "    if target_language_code == 'ja':\n",
    "        splitStr = \"。|！|？|  \"  # Split text into sentences based on period (。), exclamation mark (！), question mark (？), and double space ( )\n",
    "    else:\n",
    "        splitStr = \".|!|?|,| \"  # Split text into sentences based on period (.), exclamation mark (!), question mark (?), comma (,), and space ( )\n",
    "\n",
    "    # Use regular expression to split the text\n",
    "    sentences = re.split(f'({splitStr})', text)\n",
    "\n",
    "    # Initialize variables to store wrapped text\n",
    "    wrapped_text = ''\n",
    "    line_length = 0\n",
    "\n",
    "    # Iterate through the split sentences\n",
    "    for token in sentences:\n",
    "        # If the sentence is not empty and adding its length to the current line length does not exceed the specified width,\n",
    "        # add the sentence to the current line\n",
    "        if token and line_length + len(token) <= width:\n",
    "            wrapped_text += token\n",
    "            line_length += len(token)\n",
    "        # If the sentence is not empty, but adding its length to the current line length exceeds the specified width,\n",
    "        # add the sentence to a new line\n",
    "        elif token:\n",
    "            wrapped_text += '\\n' + token\n",
    "            line_length = len(token)\n",
    "\n",
    "    return wrapped_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
